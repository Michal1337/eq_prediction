{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "import tqdm\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1337\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_DATE_TRAIN = \"2020-01-01\"\n",
    "SPLIT_DATE_VAL = \"2023-01-01\"\n",
    "RADIUS = 300\n",
    "THRESHOLD = 750\n",
    "BLOCK_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROC_PARAMS = {\n",
    "    \"mag_low\": -1,\n",
    "    \"mag_high\": 7,\n",
    "    \"depth_low\": 2,\n",
    "    \"depth_high\": 1e8,\n",
    "    \"scale_distance\": 78.44,\n",
    "    \"scale_distance_lag\": 300,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/with_features_final.csv\")\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>longitude_disc</th>\n",
       "      <th>latitude_disc</th>\n",
       "      <th>pos</th>\n",
       "      <th>lat_cent</th>\n",
       "      <th>lon_cent</th>\n",
       "      <th>plate_region</th>\n",
       "      <th>dist_region</th>\n",
       "      <th>dist</th>\n",
       "      <th>plate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1973-01-01</td>\n",
       "      <td>-155.360833</td>\n",
       "      <td>19.443667</td>\n",
       "      <td>7.302</td>\n",
       "      <td>1.85</td>\n",
       "      <td>-156</td>\n",
       "      <td>19</td>\n",
       "      <td>19_-156</td>\n",
       "      <td>19.5</td>\n",
       "      <td>-155.5</td>\n",
       "      <td>22</td>\n",
       "      <td>3527.668174</td>\n",
       "      <td>3522.498687</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1973-01-02</td>\n",
       "      <td>-155.204333</td>\n",
       "      <td>19.326000</td>\n",
       "      <td>6.589</td>\n",
       "      <td>2.21</td>\n",
       "      <td>-156</td>\n",
       "      <td>19</td>\n",
       "      <td>19_-156</td>\n",
       "      <td>19.5</td>\n",
       "      <td>-155.5</td>\n",
       "      <td>22</td>\n",
       "      <td>3527.668174</td>\n",
       "      <td>3521.228924</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1973-01-02</td>\n",
       "      <td>-155.253167</td>\n",
       "      <td>19.314833</td>\n",
       "      <td>7.041</td>\n",
       "      <td>1.93</td>\n",
       "      <td>-156</td>\n",
       "      <td>19</td>\n",
       "      <td>19_-156</td>\n",
       "      <td>19.5</td>\n",
       "      <td>-155.5</td>\n",
       "      <td>22</td>\n",
       "      <td>3527.668174</td>\n",
       "      <td>3525.575831</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1973-01-03</td>\n",
       "      <td>-155.290167</td>\n",
       "      <td>19.399833</td>\n",
       "      <td>7.864</td>\n",
       "      <td>1.76</td>\n",
       "      <td>-156</td>\n",
       "      <td>19</td>\n",
       "      <td>19_-156</td>\n",
       "      <td>19.5</td>\n",
       "      <td>-155.5</td>\n",
       "      <td>22</td>\n",
       "      <td>3527.668174</td>\n",
       "      <td>3521.146991</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1973-01-03</td>\n",
       "      <td>-155.273667</td>\n",
       "      <td>19.408500</td>\n",
       "      <td>13.166</td>\n",
       "      <td>1.94</td>\n",
       "      <td>-156</td>\n",
       "      <td>19</td>\n",
       "      <td>19_-156</td>\n",
       "      <td>19.5</td>\n",
       "      <td>-155.5</td>\n",
       "      <td>22</td>\n",
       "      <td>3527.668174</td>\n",
       "      <td>3519.272394</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111174</th>\n",
       "      <td>2023-09-17</td>\n",
       "      <td>-16.551100</td>\n",
       "      <td>36.338800</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.30</td>\n",
       "      <td>-17</td>\n",
       "      <td>36</td>\n",
       "      <td>36_-17</td>\n",
       "      <td>36.5</td>\n",
       "      <td>-16.5</td>\n",
       "      <td>18</td>\n",
       "      <td>106.166869</td>\n",
       "      <td>123.068500</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111175</th>\n",
       "      <td>2023-09-29</td>\n",
       "      <td>-63.741300</td>\n",
       "      <td>60.600500</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.20</td>\n",
       "      <td>-64</td>\n",
       "      <td>60</td>\n",
       "      <td>60_-64</td>\n",
       "      <td>60.5</td>\n",
       "      <td>-63.5</td>\n",
       "      <td>18</td>\n",
       "      <td>1730.151056</td>\n",
       "      <td>1743.541742</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111176</th>\n",
       "      <td>2023-09-28</td>\n",
       "      <td>-110.487800</td>\n",
       "      <td>32.234100</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.10</td>\n",
       "      <td>-111</td>\n",
       "      <td>32</td>\n",
       "      <td>32_-111</td>\n",
       "      <td>32.5</td>\n",
       "      <td>-110.5</td>\n",
       "      <td>31</td>\n",
       "      <td>364.340172</td>\n",
       "      <td>356.687073</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111177</th>\n",
       "      <td>2023-09-27</td>\n",
       "      <td>93.112900</td>\n",
       "      <td>0.862200</td>\n",
       "      <td>10.000</td>\n",
       "      <td>5.50</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0_93</td>\n",
       "      <td>0.5</td>\n",
       "      <td>93.5</td>\n",
       "      <td>15</td>\n",
       "      <td>50.773571</td>\n",
       "      <td>35.611755</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111178</th>\n",
       "      <td>2023-09-26</td>\n",
       "      <td>175.282100</td>\n",
       "      <td>64.417600</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>175</td>\n",
       "      <td>64</td>\n",
       "      <td>64_175</td>\n",
       "      <td>64.5</td>\n",
       "      <td>175.5</td>\n",
       "      <td>31</td>\n",
       "      <td>389.223215</td>\n",
       "      <td>375.497885</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4111179 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time   longitude   latitude   depth   mag  longitude_disc  \\\n",
       "0        1973-01-01 -155.360833  19.443667   7.302  1.85            -156   \n",
       "1        1973-01-02 -155.204333  19.326000   6.589  2.21            -156   \n",
       "2        1973-01-02 -155.253167  19.314833   7.041  1.93            -156   \n",
       "3        1973-01-03 -155.290167  19.399833   7.864  1.76            -156   \n",
       "4        1973-01-03 -155.273667  19.408500  13.166  1.94            -156   \n",
       "...             ...         ...        ...     ...   ...             ...   \n",
       "4111174  2023-09-17  -16.551100  36.338800  10.000  4.30             -17   \n",
       "4111175  2023-09-29  -63.741300  60.600500  10.000  4.20             -64   \n",
       "4111176  2023-09-28 -110.487800  32.234100   5.000  3.10            -111   \n",
       "4111177  2023-09-27   93.112900   0.862200  10.000  5.50              93   \n",
       "4111178  2023-09-26  175.282100  64.417600  10.000  4.00             175   \n",
       "\n",
       "         latitude_disc      pos  lat_cent  lon_cent  plate_region  \\\n",
       "0                   19  19_-156      19.5    -155.5            22   \n",
       "1                   19  19_-156      19.5    -155.5            22   \n",
       "2                   19  19_-156      19.5    -155.5            22   \n",
       "3                   19  19_-156      19.5    -155.5            22   \n",
       "4                   19  19_-156      19.5    -155.5            22   \n",
       "...                ...      ...       ...       ...           ...   \n",
       "4111174             36   36_-17      36.5     -16.5            18   \n",
       "4111175             60   60_-64      60.5     -63.5            18   \n",
       "4111176             32  32_-111      32.5    -110.5            31   \n",
       "4111177              0     0_93       0.5      93.5            15   \n",
       "4111178             64   64_175      64.5     175.5            31   \n",
       "\n",
       "         dist_region         dist  plate  label  \n",
       "0        3527.668174  3522.498687   22.0      0  \n",
       "1        3527.668174  3521.228924   22.0      0  \n",
       "2        3527.668174  3525.575831   22.0      0  \n",
       "3        3527.668174  3521.146991   22.0      0  \n",
       "4        3527.668174  3519.272394   22.0      0  \n",
       "...              ...          ...    ...    ...  \n",
       "4111174   106.166869   123.068500   18.0      0  \n",
       "4111175  1730.151056  1743.541742   18.0      0  \n",
       "4111176   364.340172   356.687073   31.0      0  \n",
       "4111177    50.773571    35.611755   15.0      0  \n",
       "4111178   389.223215   375.497885   31.0      0  \n",
       "\n",
       "[4111179 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0\n",
    "    lat1 = np.radians(lat1)\n",
    "    lon1 = np.radians(lon1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    lon2 = np.radians(lon2)\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_regions(df: pd.DataFrame, threshold: int, radius: int) -> pd.DataFrame:\n",
    "    df_f = df[df[\"time\"] <= SPLIT_DATE_TRAIN]\n",
    "    regions = []\n",
    "    for pos in tqdm.tqdm(df_f[\"pos\"].unique()):\n",
    "        # tmp = df_f.copy(deep=True)\n",
    "        lat, lon = pos.split(\"_\")\n",
    "        lat, lon = float(lat), float(lon)\n",
    "        diff = int(radius / 111) + 3\n",
    "        tmp = df_f[(df_f[\"latitude\"] >= lat - diff) & (df_f[\"latitude\"] <= lat + diff) & (df_f[\"longitude\"] >= lon - diff) & (df_f[\"longitude\"] <= lon + diff)]\n",
    "        tmp[\"distance\"] = haversine_distance(tmp[\"latitude\"], tmp[\"longitude\"], lat + 0.5, lon + 0.5)\n",
    "        tmp = tmp[tmp[\"distance\"] <= radius]\n",
    "        if len(tmp) >= threshold:\n",
    "            regions.append(pos)\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df, PREPROC_PARAMS, SPLIT_DATE_TRAIN):\n",
    "    scaler_dict = {}\n",
    "    df_train = df[df[\"time\"] < SPLIT_DATE_TRAIN]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    mag = np.clip(df_train[\"mag\"].values, PREPROC_PARAMS[\"mag_low\"], PREPROC_PARAMS[\"mag_high\"])\n",
    "    scaler.fit(mag.reshape(-1, 1))\n",
    "    df[\"mag\"] = scaler.transform(np.clip(df[\"mag\"].values, PREPROC_PARAMS[\"mag_low\"], PREPROC_PARAMS[\"mag_high\"]).reshape(-1, 1))\n",
    "    scaler_dict[\"mag\"] = scaler\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    depth = np.log(df_train[\"depth\"] + np.abs(df[\"depth\"].min()) + 1).values\n",
    "    depth = np.clip(depth, PREPROC_PARAMS[\"depth_low\"], PREPROC_PARAMS[\"depth_high\"])\n",
    "    scaler.fit(depth.reshape(-1, 1))\n",
    "    df[\"depth\"] = np.log(df[\"depth\"] + np.abs(df[\"depth\"].min()) + 1)\n",
    "    df[\"depth\"] = scaler.transform(np.clip(df[\"depth\"].values, PREPROC_PARAMS[\"depth_low\"], PREPROC_PARAMS[\"depth_high\"]).reshape(-1, 1))\n",
    "    scaler_dict[\"depth\"] = scaler\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_train[\"latitude\"].values.reshape(-1, 1))\n",
    "    df[\"latitude_new\"] = scaler.transform(df[\"latitude\"].values.reshape(-1, 1))\n",
    "    scaler_dict[\"latitude_new\"] = scaler\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_train[\"longitude\"].values.reshape(-1, 1))\n",
    "    df[\"longitude_new\"] = scaler.transform(df[\"longitude\"].values.reshape(-1, 1))\n",
    "    scaler_dict[\"longitude_new\"] = scaler\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_train[\"lat_cent\"].values.reshape(-1, 1))\n",
    "    df[\"lat_cent\"] = scaler.transform(df[\"lat_cent\"].values.reshape(-1, 1))\n",
    "    scaler_dict[\"lat_cent\"] = scaler\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_train[\"lon_cent\"].values.reshape(-1, 1))\n",
    "    df[\"lon_cent\"] = scaler.transform(df[\"lon_cent\"].values.reshape(-1, 1))\n",
    "    scaler_dict[\"lon_cent\"] = scaler\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    dist = np.log(df_train[\"dist\"] + 1).values.reshape(-1, 1)\n",
    "    scaler.fit(dist)\n",
    "    df[\"dist\"] = scaler.transform(np.log(df[\"dist\"] + 1).values.reshape(-1, 1))\n",
    "    scaler_dict[\"dist\"] = scaler\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    dist_region = np.log(df_train[\"dist_region\"] + 1).values.reshape(-1, 1)\n",
    "    scaler.fit(dist_region)\n",
    "    df[\"dist_region\"] = scaler.transform(np.log(df[\"dist_region\"] + 1).values.reshape(-1, 1))\n",
    "    scaler_dict[\"dist_region\"] = scaler\n",
    "\n",
    "    return df, scaler_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_block(df, pos, radius, block_size, PREPROC_PARAMS):\n",
    "    bins = [0, 1, 2, 3, 4, 5, 6, 7, 10, 14, 21, 30, 60, 180, 1e8]\n",
    "    lat, lon = pos.split(\"_\")\n",
    "    lat, lon = float(lat), float(lon)\n",
    "    tmp1 = df[df[\"pos\"] == pos]\n",
    "    diff = int(radius / 111) + 3\n",
    "    tmp2 = df[((df[\"latitude\"] >= lat - diff) & (df[\"latitude\"] <= lat + diff) & (df[\"longitude\"] >= lon - diff) & (df[\"longitude\"] <= lon + diff)) & (df[\"pos\"] != pos)]\n",
    "    tmp2[\"label\"] = -1\n",
    "    tmp = pd.concat([tmp1, tmp2], axis=0)\n",
    "    tmp[\"distance\"] = haversine_distance(tmp[\"latitude\"], tmp[\"longitude\"], lat + 0.5, lon + 0.5)\n",
    "    tmp = tmp[tmp[\"distance\"] <= radius]\n",
    "    tmp.sort_values(by=[\"time\"], inplace=True)\n",
    "    tmp[\"diff_days\"] = (tmp[\"time\"] - tmp[\"time\"].shift(1)).dt.days\n",
    "    tmp[\"diff_days\"] = np.digitize(tmp[\"diff_days\"], bins=bins) - 1\n",
    "    for idx in range(1, block_size):\n",
    "        tmp[\"mag_\" + str(idx)] = tmp[\"mag\"].shift(idx)\n",
    "        tmp[\"depth_\" + str(idx)] = tmp[\"depth\"].shift(idx)\n",
    "        tmp[\"latitude_new_\" + str(idx)] = tmp[\"latitude_new\"].shift(idx)\n",
    "        tmp[\"longitude_new_\" + str(idx)] = tmp[\"longitude_new\"].shift(idx)\n",
    "        tmp[\"dist_\" + str(idx)] = tmp[\"dist\"].shift(idx)\n",
    "        tmp[\"distance_\" + str(idx)] = tmp[\"distance\"].shift(idx) / PREPROC_PARAMS[\"scale_distance_lag\"]\n",
    "        tmp[\"plate_\" + str(idx)] = tmp[\"plate\"].shift(idx)\n",
    "        tmp[\"diff_days_\" + str(idx)] = tmp[\"diff_days\"].shift(idx)\n",
    "    tmp = tmp[tmp[\"label\"] != -1]\n",
    "    tmp[\"distance\"] = tmp[\"distance\"] / PREPROC_PARAMS[\"scale_distance\"]\n",
    "    tmp.dropna(inplace=True)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(df, block_size, feature_order, featrues_region):\n",
    "    df = df.sample(frac=1, random_state = SEED).reset_index(drop=True)\n",
    "    x_train = df[feature_order].to_numpy().reshape(-1, block_size, len(feature_order) // block_size)\n",
    "    x_region = df[featrues_region].to_numpy().reshape(-1, len(featrues_region))\n",
    "    y_train = df[\"label\"].to_numpy().reshape(-1, 1)\n",
    "    return x_train, x_region, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_all(df, block_size, feature_order, features_region, SPLIT_DATE_TRAIN, SPLIT_DATE_VAL):\n",
    "    df_train = df[df[\"time\"] < SPLIT_DATE_TRAIN]\n",
    "    df_val = df[(df[\"time\"] >= SPLIT_DATE_TRAIN) & (df[\"time\"] < SPLIT_DATE_VAL)]\n",
    "    df_test = df[df[\"time\"] >= SPLIT_DATE_VAL]\n",
    "    x_train, x_train_region, y_train = reshape(df_train, block_size, feature_order, features_region)\n",
    "    x_val, x_val_region, y_val = reshape(df_val, block_size, feature_order, features_region)\n",
    "    x_test, x_test_region, y_test = reshape(df_test, block_size, feature_order, features_region)\n",
    "    return x_train, x_train_region, y_train, x_val, x_val_region, y_val, x_test, x_test_region, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_npys(df, radius, th, block_size, features_order, features_region, PREPROC_PARAMS, SPLIT_DATE_TRAIN, SPLIT_DATE_VAL):\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], format=\"mixed\")\n",
    "    df.sort_values(by=\"time\", inplace=True)\n",
    "    regions = filter_regions(df, th, radius)\n",
    "    df, scaler_dict = preprocess_df(df, PREPROC_PARAMS, SPLIT_DATE_TRAIN)\n",
    "    np.random.shuffle(regions)\n",
    "    for idx, pos in enumerate(tqdm.tqdm(regions)):\n",
    "        df_pos = make_block(df, pos, radius, block_size, PREPROC_PARAMS)\n",
    "        x_train, x_train_region, y_train, x_val, x_val_region, y_val, x_test, x_test_region, y_test = split_all(df_pos, block_size, features_order, features_region, SPLIT_DATE_TRAIN, SPLIT_DATE_VAL)\n",
    "        np.save(\"../data/npys/x_train_\" + str(idx) + \".npy\", x_train)\n",
    "        np.save(\"../data/npys/x_train_region_\" + str(idx) + \".npy\", x_train_region)\n",
    "        np.save(\"../data/npys/y_train_\" + str(idx) + \".npy\", y_train)\n",
    "        np.save(\"../data/npys/x_val_\" + str(idx) + \".npy\", x_val)\n",
    "        np.save(\"../data/npys/x_val_region_\" + str(idx) + \".npy\", x_val_region)\n",
    "        np.save(\"../data/npys/y_val_\" + str(idx) + \".npy\", y_val)\n",
    "        np.save(\"../data/npys/x_test_\" + str(idx) + \".npy\", x_test)\n",
    "        np.save(\"../data/npys/x_test_region_\" + str(idx) + \".npy\", x_test_region)\n",
    "        np.save(\"../data/npys/y_test_\" + str(idx) + \".npy\", y_test)\n",
    "    return scaler_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_region = [\"lat_cent\", \"lon_cent\", \"dist_region\", \"plate_region\"]\n",
    "featrues = [\"mag\", \"depth\", \"latitude_new\", \"longitude_new\", \"dist\", \"distance\", \"plate\", \"diff_days\"]\n",
    "featrues_order = [featrues[idx] + \"_\" + str(i) for i in range(BLOCK_SIZE-1, 0, -1) for idx in range(len(featrues))]\n",
    "featrues_order = featrues_order + featrues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1378/1378 [35:03<00:00,  1.53s/it] \n"
     ]
    }
   ],
   "source": [
    "scalers = make_npys(df.copy(deep=True), RADIUS, THRESHOLD, BLOCK_SIZE, featrues_order, features_region, PREPROC_PARAMS, SPLIT_DATE_TRAIN, SPLIT_DATE_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scalers\n",
    "with open(\"../data/scalers_for_npys.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scalers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
